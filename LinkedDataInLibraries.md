by David F. Flanders

## Summary ##
There was some pre-reading sent prior to, including an article on,  ["Linked Data - The Story so Far" - PDF](http://wwwtomheath.com/papers/bizer-heath-berners-lee-ijswis-linked-data.pdf) (which is worth a read for those who want an exec overview of how linkeddata came about).

Day one was kicked off with an explanation of Linkeddata by Nigel Shadbolt.  It was followed by three case studies: 1.) The National Library of Sweeden's experience with exposing their bibliographic metadata as linkeddata, 2.) Talis presented their work on behalf of the BBC in exposing their wildlife site as linkeddata (and subsequent additional BBC projects that will be adopting it), and 3.) The JISC's Vocabulary Mapping Project (which while theoretical was an interesting look into the problems of creating metadata crosswalks with linkeddata in the future. The afternoon broke up into discussion groups on: a.) scholarly communication, b.) digitised content and c.) bibliographic content.

Day two had Nigel Shadbolt facilitating the schedule of the day based on the notes from the previous afternoon's discussion groups and trying to come up with "SWAT teams" that could take forward immediate actions.  These groups were trying to create action re linkeddata for: national libraries, research libraries, archives, and bibliographic content .  I was split off into the 'archives' group, as the EAD vocabulary appeared to be particularly low hanging fruit with regard to being easily adaptable as a vocabulary( aka ontology).

# Key Issues (IMHO) #

This meeting was very much a kind of 'Executive Summary' on linkeddata for managers of high profile in national and research libraries.  It spent the first half day training up senior managers in the key issues which would be faced in utilising linkeddata in their libraries.

Michael Kellar (Stanford) is the most influential advocate for this international work in linkeddata, partnering with commercial companies such as FreeBase (Brian Karlak) to expose Stanford's bibliographic collection.  Other libraries seem to be waiting on further evidence or collaboration opportunities prior to committing significant resources, though they are looking to experiment and engage where opportunities arise (to note: CERN, the National Libraries of Hungary and Siwtzerland and Stanford University Library are actively devoting resources to this work already).

  * The primary meme of the event was "just do it" (in comparison to "form another committee to talk about it").  Brindley, Shadbolt and Keller all advocated this attitude and wanted actions to arise from the two days based on good will by the participants.  I personally saw a couple of actions arise from the small group discussions, including active engagement by Oxford (David Price) and Europeana in wanting to take forward ontology work for the Encoded Archival Description vocabulary.  To note: I don't know if it was the mix of meetings both inside and outside or demonstration that libraries are looking to be less risk averse, but there seemed to be a general positivism for finding resources to experiment with linkeddata despite economic times.  Obviously, this positions JISC's upcoming linkeddata work (jiscEXPO, RDTF and jiscMRD) projects ahead of the curve, in fact the recently funded jiscEXPO projects were referred to several times throughout the event as examples of 'just doing it' and worth watching accordingly. JISC reputation for pushing into the innovation space was recognised publically by Les Carr who was one of the discussion chairs.  Further info regarding actions arising are below.

  * Nigel Shadbolt at the start of day two asked for a vote on which libraries were willing to find parts of their budgets to experiment with linkeddata.  From this vote (about 3/4 said raised their hands that "they could"). Nigel also asked where this money might be spliced from to test linkeddata.  It was commonly agreed in an open discussion, that Libraries currently spend their "technician" budgets on cataloguing activities.  Furthermore, it was recognised that the current process of cataloguing was not working as many of the libraries had backlogs for cataloguing items in the thousands if not hundreds of thousands.

  * The BBC's recent mantra of "One Web" was discussed in terms of how BBC is automatically importing linkeddata into their sites from external web sites such as Wikipedia and MusicBrainz, and in doing so are also requesting that their cataloguers don't edit metadata on their own in-house systems, but rather go to Wikipedia and MusicBrainz to make edits on those external sites (which can then auto-populate back into the BBC systems).

  * Another interesting insight was the general agreement that the past couple of years have revealed that no library is an island and that the citizen librarians needed to be engaged, e.g. an excellent point was that that there will always be more staff (cataloguers, developers, etc) outside the four walls of the library than there will be within the four walls.  This also brought to question the role of the staff member who were inside the four walls and their role of either doing the work or if it should instead by upon organising those outside the four walls to do it?  Examples of Wikipedia's small staff who are enablers of volunteer citizen editors as opposed to editors themselves.

  * Licensing (surprisingly), didn't crop up until the second day when discussions around "meshups" (a 'meshup' is a "mashup" but using data from across the linkeddata Web) were being discussed in terms of provenance.  Being able to track multiple granular pieces of data from around the Web back to the original source is not easily achievable in the current linkeddata Web (especially once several repurposed generations of the data have been 're-meshed-up'); the implications for this was that for current linkeddata collection licenses such as [Creative-Commons-ZERO or more effectively the PPDL or ODbL](http://www.opendefinition.org/licenses/)  should be used, so issues around ATTRIBUTION do not stop people from "meshing-up" data from multiple resources.  Many librarians were concerned about this especially on behalf of their user populace of researchers whose primary currency was/is attribution.

  * Further to the IPR discussion was Stanford's experience of exposing their bibliographic metadata through FreeBase.  In this case, Kellar insisted that bibliographic records were "facts" and were therefore not copyrightable and could not be owned by the library.  This has not been tested in case law in either the US or UK.  There were a few minor exception such as classification schemes which might label books as "holocaust deniers" as being liable.  Though for the most part there was no objection that libraries **are** trusted because they strive to produce data that **are** facts. Fortunately, the typical IPR conversation was only about a half hour in discussion before the meeting returned back to achieving immediate actions (perhaps because of the 'just do it' attitude).

  * The collections of resources that were spoken about in terms of being low hanging fruit for being applied to the linkeddata Web included author name data (Authority Name Files, ORCID and Names), out-of-copyright material (images, newspapers, ephemeral, etc) and metadata schemas (DC, MARC, EAD, TEI, etc).  Regarding the last of these, the discussion I sat in on took EAD (Encoded Archival Description) as being a noteworthy vocabulary that could easily be turned into an ontology that could be used by several open and out of copyright archival collections right now (projects including current CLIR funded projects [link](link.md) and JISC projects were mentioned).

  * Other issues for concern discussed were:
    * BUSINESS MODELS:  Concerns for both library business models (3rd stream funding, e.g. BL's selling of their bibliographic records) and for pro active business relationship models with the exposed data were recognised.
    * SCALABILITY / ARCHITECTURE: I had one-to-one conversations with developers from the National Library of Sweeden (Markus Skold) and the Japanese National Institute of Informatics (Akihiko Takano) regarding their technical architecture.  Both these institutions moved over to linkeddata as a step-by-step process rather than just replacing their current systems with linkeddata hardware/infrastructure, e.g. a triplestore-database.  This resulted in the above two institutions still having a relational-databases at the bottom end of their infrastructure stack, thereby outputting data (via SQL queries) as structured data for end user interfaces (e.g. XML+CSS=HTML), and also then outputting (via SQL queries) another set of structured data which can then be transformed into RDF (XML+XSLT=>RDF), which in turn is then available as an open API for the developer to query (using SPARQL).  This is in opposition to more traditional linkeddata architecture that would swap out the relational databases for triplestore-databases thereby exposing a SPARQL query endpoint that could then be queried and be built into user interfaces (eg SPARQL => +X[HTML](HTML.md)).  Though the latter is where problems have occurred with regards to robustness and scalability of queries against the triple-store database.  It is worth noting that Skold mentioned that once they understood the advantages of utilising RDF they might well have chosen to go with RDF from the outset rather than a gradual shift (though the lessons learned in shifting over and acclimating the technical staff were obviously valuable.
    * TRUST / SPAM: Librarians expressed a concern about how they would express their data in an open Web and be seen as the authority figure on it.  Also, regarding untrusted entities who would use the data for spamming purposes.  This conversation was mostly speculation as it was suggested that the linkeddata Web is too young (eqv of ~1997 Web currently?).
    * CENTRAL VS DISTRIBUTTED LINKEDDATA: Several players are making an effort to be teh central providers of linkeddata for specific data collections.  For example Europeana was present and looking to harvest metadata and then re-expose as linkeddata, Talis was actively providing encouraging organisation to upload data, ORCID via the publishers were making similar claims as was RKB store.  Most agreed it was too early in the game, though several librarians obviously did not want the hassle of undergoing another format conversation and were interested in a central service that could do it for them.

[For all links cited in the above report please click here for a full set of delicious links](http://delicious.com/DFFlanders/linkeddata+bl)